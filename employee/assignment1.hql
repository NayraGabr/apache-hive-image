create database assign1;
describe database extended assign1;
create database assign1_loc location 'hdfs://namenode:8020/user/hive/warehouse/nayra/assign2.db';
create table assign1.assign1_intern_tab (eid int, ename string, age int, jobtype string, storeid int, storelocation string, salary bigint, yrsofexp int) row format delimited fields terminated by ',';
describe formatted assign1.assign1_intern_tab;
load data local inpath 'employee.csv' into table assign1.assign1_intern_tab;
!hadoop fs -put employee.csv /nayieraAssignment1;
load data inpath '/nayieraAssignment1' into table assign1.assign1_intern_tab;
select * from assign1.assign1_intern_tab limit 10;
create external table assign1_loc.assign1_external_tab (eid int, ename string, age int, jobtype string, storeid int, storelocation string, salary bigint, yrsofexp int) row format delimited fields terminated by ',' location '/nayieraAssignment1';
describe formatted assign1_loc.assign1_external_tab;
!hadoop fs -put employee.csv /nayieraAssignment1;
drop table assign1.assign1_intern_tab;
drop table assign1_loc.assign1_external_tab;
create table assign1.assign1_intern_tab (eid int, ename string, age int, jobtype string, storeid int, storelocation string, salary bigint, yrsofexp int) row format delimited fields terminated by ',';
create external table assign1_loc.assign1_external_tab (eid int, ename string, age int, jobtype string, storeid int, storelocation string, salary bigint, yrsofexp int) row format delimited fields terminated by ',' location '/nayieraAssignment';
describe formatted assign1.assign1_intern_tab;
describe formatted assign1_loc.assign1_external_tab;
create table assign1.staging (eid int, ename string, age int, jobtype string, storeid int, storelocation string, salary bigint, yrsofexp int) row format delimited fields terminated by ',';
load data local inpath 'employee.csv' into table assign1.staging;
insert into assign1.assign1_intern_tab select * from assign1.staging;
insert into table assign1_loc.assign1_external_tab select * from assign1.staging;
!hadoop fs -ls / hdfs://namenode:8020/user/hive/warehouse/assign1.db/assign1_intern_tab;
!hadoop fs -ls hdfs://namenode:8020/nayieraAssignment; 
!wc -l songs.csv;
create table songs_tab (artist_id string, artist_latitude string, artist_location string, artist_longitude string, artist_name string, duration string, num_songs string, song_id string, title string, year string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde';
load data local inpath 'songs.csv' into table songs_tab;
select * from songs_tab limit 10; 
select count(*) from songs_tab;
create external table songs_tab_external (artist_id string, artist_latitude string, artist_location string, artist_longitude string, artist_name string, duration string, num_songs string, song_id string, title string, year string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' location '/nayiera2Assignment' ;
!hadoop fs -put songs.csv /nayiera2Assignment;
select * from songs_tab_external limit 10;
drop table if exists songs_tab_external;
create external table songs_tab_external (artist_id string, artist_latitude string, artist_location string, artist_longitude string, artist_name string, duration string, num_songs string, song_id string, title string, year string) row format serde 'org.apache.hadoop.hive.serde2.OpenCSVSerde' location '/nayiera3Assignment' ;
load data local inpath 'songs.csv' into table songs_tab_external;
use assign1;
alter table assign1_intern_tab rename to assign1_loc.assign1_intern_tab;
describe formatted assign1_loc.assign1_intern_tab;
select * from assign1_loc.assign1_intern_tab;